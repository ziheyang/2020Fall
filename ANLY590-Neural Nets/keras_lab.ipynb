{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jS47B8K0JLkx"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow.keras.layers as tfkl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iehoGWa6SSWU"
   },
   "source": [
    "### regression\n",
    "\n",
    "Let's start by using `keras` to make a neural network for a simple regression task where both the input and the output as 1-dimensional. Below is some code that will produce the dataset for you to train on.\n",
    "\n",
    "Here are some general steps to follow:\n",
    "1. Define your model by passing `tfk.Sequential` a list of layers (found in `tf.keras.layers`, which is already imported for you by the shorter name `tfkl`, since you will use this module many times.\n",
    "2. Your first layers should be a `tfkl.Input` layer that specifies the shape of the input (it will automatically include an empty first dimension with size `None` as a placehold for the batch size).\n",
    "3. The rest of your layers should be `tfkl.Dense` layers; you will be to specify the number of neurons/units as well as the activation function (you can find those in `tf.nn`, and you can use `None` for a \"linear\" activation function, $f(x)=x$). Make sure you pick an output function that makes sense for this prediction task!\n",
    "4. Choose an appropriate optimizer from `tfk.optimizers` and an appropriate loss function from `tfk.losses` (both are classes that wil need to be initialized), and then pass them to `model.compile` to compile your model.\n",
    "5. Call `model.fit` to fit your model and collect the results\n",
    "6. Plot your training curve (loss vs training step)\n",
    "7. Call your model (`model(...)`) on a grid of inputs (code to make the grid provided) and plot the relationship your model learned against the true relationship (defined as `f` in the code below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDgsWoAKJbxz"
   },
   "outputs": [],
   "source": [
    "def regression_data(N):\n",
    "    x = np.random.uniform(low=-5.0, high=5.0, size=(N, 1)).astype(np.float32)\n",
    "    e = 0.2 * np.random.normal(size=(N, 1)).astype(np.float32)\n",
    "    f = lambda x: 0.2 * x**2 * np.sin(2 * np.pi * x / 6)\n",
    "    y = f(x) + e\n",
    "    return x, y\n",
    "\n",
    "N = 100\n",
    "x, y = regression_data(N)\n",
    "\n",
    "plt.scatter(x, y, s=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBzgG7E0KmFR"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pULO0BniMAL2"
   },
   "outputs": [],
   "source": [
    "x_grid = np.linspace(x.min(), x.max(), 200).astype(np.float32)[:, np.newaxis]\n",
    "y_true = f(x_grid)\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dc59MczHVrc9"
   },
   "source": [
    "### binary classification\n",
    "\n",
    "Here is another dataset that differs in two key ways from the regression example we just worked:\n",
    "1. The input is now 2-dimensional\n",
    "2. The targets are now binary classes\n",
    "\n",
    "Update your model to handle both of these changes and try fitting this new data. Think about the following:\n",
    "- input shape\n",
    "- output function\n",
    "- loss function\n",
    "\n",
    "Since visualizing the results is a bit tricky, we have provided some code for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NMg8n9NRGo_9"
   },
   "outputs": [],
   "source": [
    "N = 200\n",
    "def binary_classification_data(N):\n",
    "    x = np.random.uniform(low=-5, high=5, size=(N, 2))\n",
    "    y = (x[:, 0] * x[:, 1] > 0).astype(np.int)\n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = binary_classification_data(N)\n",
    "x_test, y_test = binary_classification_data(N)\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(x_train[:, 0], x_train[:, 1], s=10, c=y_train, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4P6Ez3VJzQk"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ZUclc8PKqEC"
   },
   "outputs": [],
   "source": [
    "def binary_preds(model, x_minmax=5):\n",
    "    x_grid = np.linspace(-x_minmax, x_minmax, 100)\n",
    "    mesh = np.meshgrid(x_grid, x_grid)\n",
    "    xs_grid = np.stack(mesh, axis=-1)\n",
    "    yhat = model(xs_grid).numpy().squeeze()\n",
    "\n",
    "\n",
    "    plt.imshow(yhat, cmap='coolwarm')\n",
    "    plt.colorbar()\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6NPT8dsWWXW"
   },
   "source": [
    "### general classfication\n",
    "\n",
    "Finally we will download and train on some real data to learn about general classification. Here is some code that will download and show some metadata about the MNIST dataset -- a collectin of handwritten digits.\n",
    "\n",
    "Update your model to work on this data so that you model can predict the digit from its image. One new thing to keep in mind: these inputs are 2D. Later in the course we will learn about convolutional neural nets for handing such inputs more naturally, but for now, update your `tfkl.Input` layer to be 2-dimensional and then add a `tfkl.Flatten()` layer right after it to unravel the 2-d image into a 1-d vector of pixels.\n",
    "\n",
    "Again, visualalizing the output is a bit tricky, so we have provided some code to help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQl7DZmBNvm_"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "ds, metadata = tfds.load('mnist', with_info=True)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bKre0z2HOCDm"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJ17dcdQOt_w"
   },
   "outputs": [],
   "source": [
    "mnist_viz(model):\n",
    "  ims, labels = next(iter(ds['test'].unbatch().batch(10)))\n",
    "  yhat = model(ims)\n",
    "  ypred = tf.argmax(yhat)\n",
    "\n",
    "  plt.figure(figsize=(10, 40))\n",
    "  for i in range(10):\n",
    "    plt.subplot(10, 2, 2*i+1)\n",
    "    plt.imshow(ims[i].numpy().squeeze(), cmap='bone')\n",
    "    plt.subplot(10, 2, 2*i+2)\n",
    "    plt.bar(np.arange(10), yhat[i].numpy())\n",
    "    plt.ylim([0, 1])\n",
    "  plt.show()\n",
    "\n",
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "Copy of keras-lab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
